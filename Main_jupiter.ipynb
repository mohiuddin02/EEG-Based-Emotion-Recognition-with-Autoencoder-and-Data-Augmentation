{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fAYBRDIH3hKC",
        "colab": {}
      },
      "source": [
        "#importing all the neccessary libraries\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, Reshape, Flatten, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#########################################\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSad1dh6_qJp",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2PKfa1aB3hKH",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D, Reshape\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#from tensorflow.keras.utils\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, RobustScaler, StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1-isct2W7bjv",
        "outputId": "19173cc8-dd79-406a-ea52-997163b330dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IZPeHhIK7YsF",
        "outputId": "bb289600-df84-4aca-e23a-abda1adaffee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9aTuB4UY8dYx",
        "outputId": "0dd7d2e9-fdc2-4d8f-c8c5-21df7efaaea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/\"My Drive\"/\"Colab Notebooks\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uTh9lOY43hKJ",
        "colab": {}
      },
      "source": [
        "# Load_data is already attached in the zip file\n",
        "import load_data\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# return DataSet class\n",
        "data = load_data.read_data_sets(one_hot=True)\n",
        "\n",
        "# get train data and labels\n",
        "x_train, y_train = data.train.next_batch(84420)\n",
        "\n",
        "# get test data\n",
        "x_test = data.test.data\n",
        "\n",
        "# get test labels\n",
        "y_test = data.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrnOFdYB3hKL",
        "colab": {}
      },
      "source": [
        "#transforming the brain signal data into image data with  a dimension of 9x9\n",
        "def transfor(dataset, w):\n",
        "    im = np.zeros([9, 9])\n",
        "    im[0, 3] = dataset[0]\n",
        "    im[0, 4] = dataset[1]\n",
        "    im[0, 5] = dataset[2]\n",
        "    \n",
        "    im[1, 3] = dataset[3]\n",
        "    im[1, 5] = dataset[4]\n",
        "\n",
        "    im[2, 0] = dataset[5]\n",
        "    im[2, 1] = dataset[6]\n",
        "    im[2, 2] = dataset[7]\n",
        "    im[2, 3] = dataset[8]\n",
        "    im[2, 4] = dataset[9]\n",
        "    im[2, 5] = dataset[10]\n",
        "    im[2, 6] = dataset[11]\n",
        "    im[2, 7] = dataset[12]\n",
        "    im[2, 8] = dataset[13]\n",
        "\n",
        "    im[3, 0] = dataset[14] * w ##\n",
        "    im[3, 1] = dataset[15]\n",
        "    im[3, 2] = dataset[16]\n",
        "    im[3, 3] = dataset[17]\n",
        "    im[3, 4] = dataset[18]\n",
        "    im[3, 5] = dataset[19]\n",
        "    im[3, 6] = dataset[20]\n",
        "    im[3, 7] = dataset[21]\n",
        "    im[3, 8] = dataset[22] * w ##\n",
        "\n",
        "    im[4, 0] = dataset[23] * w ##\n",
        "    im[4, 1] = dataset[24] * w ##\n",
        "    im[4, 2] = dataset[25]\n",
        "    im[4, 3] = dataset[26]\n",
        "    im[4, 4] = dataset[27]\n",
        "    im[4, 5] = dataset[28]\n",
        "    im[4, 6] = dataset[29]\n",
        "    im[4, 7] = dataset[30] * w ##\n",
        "    im[4, 8] = dataset[31] * w ##\n",
        "\n",
        "    im[5, 0] = dataset[32] * w ##\n",
        "    im[5, 1] = dataset[33] * w ##\n",
        "    im[5, 2] = dataset[34]\n",
        "    im[5, 3] = dataset[35]\n",
        "    im[5, 4] = dataset[36]\n",
        "    im[5, 5] = dataset[37]\n",
        "    im[5, 6] = dataset[38]\n",
        "    im[5, 7] = dataset[39] * w ##\n",
        "    im[5, 8] = dataset[40] * w ##\n",
        "\n",
        "    im[6, 0] = dataset[41] * w ##\n",
        "    im[6, 1] = dataset[42]\n",
        "    im[6, 2] = dataset[43]\n",
        "    im[6, 3] = dataset[44]\n",
        "    im[6, 4] = dataset[45]\n",
        "    im[6, 5] = dataset[46]\n",
        "    im[6, 6] = dataset[47]\n",
        "    im[6, 7] = dataset[48]\n",
        "    im[6, 8] = dataset[49] * w ##\n",
        "\n",
        "    im[7, 1] = dataset[50]\n",
        "    im[7, 2] = dataset[51]\n",
        "    im[7, 3] = dataset[52]\n",
        "    im[7, 4] = dataset[53]\n",
        "    im[7, 5] = dataset[54]\n",
        "    im[7, 6] = dataset[55]\n",
        "    im[7, 7] = dataset[56]\n",
        "\n",
        "    im[8, 2] = dataset[57]\n",
        "    im[8, 3] = dataset[58]\n",
        "    im[8, 4] = dataset[59]\n",
        "    im[8, 5] = dataset[60]\n",
        "    im[8, 6] = dataset[61]\n",
        "\n",
        "    im = im.reshape(im.shape[0], im.shape[1], 1)\n",
        "    return im\n",
        "        \n",
        "def convert(d,l):\n",
        "    images = []\n",
        "    labels = []\n",
        "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
        "    d = min_max_scaler.fit_transform(d.T).transpose()\n",
        "    for i in range(d.shape[0]):\n",
        "        label = l[i]\n",
        "        image = convert2img(d[i])\n",
        "        images.append(image)\n",
        "\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "# each row contains 310 values, the rows are splitted were every 62 values of each row are multipled with a weight of 1.2    \n",
        "def convert2img(datarow):\n",
        "    w = 1.2\n",
        "    f0 = transfor(datarow[:62], w)\n",
        "    f1 = transfor(datarow[62:124], w)\n",
        "    f2 = transfor(datarow[124:186], w)\n",
        "    f3 = transfor(datarow[186:248], w)\n",
        "    f4 = transfor(datarow[248:310], w)\n",
        "    # finally all the parts of each row are concatenated to form the image\n",
        "    image = np.concatenate((f0, f1, f2, f3, f4), axis=2)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jPXAjw443hKN",
        "colab": {}
      },
      "source": [
        "#calling the convert function to convert the brain signal data into image data\n",
        "x_trainImg, y_trainImg = convert(x_train, y_train)\n",
        "\n",
        "x_testImg, y_testImg = convert(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NxSKez893hKQ",
        "outputId": "6561ab37-b7bc-4c73-d60a-a20f01a690ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#image has a dimension of 9x9 with 5 channels\n",
        "print(x_trainImg.shape, y_trainImg.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(84420, 9, 9, 5) (84420, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XMiPYGq23hKS",
        "colab": {}
      },
      "source": [
        "def create_block(input, channel): ## Convolution block of 2 layers to be used in auto encoder and classifier\n",
        "    x = input\n",
        "    for i in range(2):\n",
        "        x = Conv2D(channel, 3, padding=\"same\")(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwb3dykK5Kuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = Input((9,9,5))\n",
        "    \n",
        "    # Encoder\n",
        "block1 = create_block(input, 32)\n",
        "x = MaxPool2D(2)(block1)\n",
        "block2 = create_block(x, 64)\n",
        "x = MaxPool2D(2)(block2)\n",
        "    #middle\n",
        "middle = create_block(x, 128)\n",
        "    \n",
        "    # Decoder\n",
        "up1 = UpSampling2D((3,3))(middle)\n",
        "block3 = create_block(up1, 64)\n",
        "   \n",
        "up2 = UpSampling2D((3,3))(block3)\n",
        "block4 = create_block(up2, 32)\n",
        "up2 = MaxPool2D(2)(block4)\n",
        "    \n",
        "    # output\n",
        "x = Conv2D(5, 1)(up2)\n",
        "output = Activation(\"sigmoid\")(x)\n",
        "\n",
        "models =  Model(input, middle) #e\n",
        "model = Model(input, output)\n",
        "#compiling the autoencoder\n",
        "model.compile(Adam(0.001, 0.9), loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uGri6SBA3hKU",
        "outputId": "3a38a4a8-74eb-40d2-db52-98c7b7f3e6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 9, 9, 5)]         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 9, 9, 32)          1472      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 9, 9, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 9, 32)          9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 9, 9, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2, 2, 128)         512       \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 64)          73792     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 18, 18, 32)        18464     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 18, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 18, 18, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 18, 18, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 18, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 18, 18, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 9, 9, 5)           165       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 9, 9, 5)           0         \n",
            "=================================================================\n",
            "Total params: 428,741\n",
            "Trainable params: 427,461\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DdEVWtC63hKW",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_trainImg, x_trainImg, \n",
        "                       batch_size=512,\n",
        "                       epochs=100,\n",
        "                       verbose=1,\n",
        "                       validation_data=(x_testImg, x_testImg),\n",
        "                       shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y6b3L34y3hKY",
        "colab": {}
      },
      "source": [
        "#extracting the bottleneck features by predicting the images from the encoder and middle layer\n",
        "predict_train = models.predict(x_trainImg)\n",
        "\n",
        "predict_test = models.predict(x_testImg)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpQia6FW3hKa",
        "colab": {}
      },
      "source": [
        "#classifier \n",
        "input = Input((predict_train.shape[1], predict_train.shape[2], predict_train.shape[3]))\n",
        "x = Conv2D(1024, 3, padding=\"same\")(input)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "    # x = Conv2D(128, 3, padding=\"same\")(x)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "    # x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.35)(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dropout(0.69)(x)\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "Models = Model(input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S94B2rYR5DRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "4341c715-8411-4811-c4b0-36d2df2ad9cc"
      },
      "source": [
        "Models.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 2, 2, 128)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 2, 1024)        1180672   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 2, 2, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 1,765,267\n",
            "Trainable params: 1,761,171\n",
            "Non-trainable params: 4,096\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OS5ViPkl3hKc",
        "colab": {}
      },
      "source": [
        "#initializing the inputs of the train and test data with images predicted from the encoder layer\n",
        "train_datagen = ImageDataGenerator(shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "train_set = train_datagen.flow(predict_train, y_trainImg, batch_size=512)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_set = test_datagen.flow(predict_test,y_testImg, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_xEVqrt_3hKe",
        "outputId": "c5af3a47-6fea-4b33-b6f8-a75984a1d403",
        "colab": {}
      },
      "source": [
        "#training the classifier model by fitting the model with \n",
        "#image generator and running the model 3 times\n",
        "a = []\n",
        "size = np.ceil(x_testImg.shape[0]/1024)\n",
        "for x in range(3):\n",
        "    print(\"For run : \" + str(x))\n",
        "    \n",
        "    Models.compile(loss='categorical_crossentropy',\n",
        "                            optimizer=Adam(),\n",
        "                            metrics=['accuracy'])\n",
        "    \n",
        "    AutoencoderConvClassifierImageGenerator = Models.fit_generator(train_set,\n",
        "                            epochs=100,\n",
        "                            steps_per_epoch=np.ceil(x_trainImg.shape[0]/1024),\n",
        "                            verbose=1,\n",
        "                            validation_data=(test_set),\n",
        "                            validation_steps=np.ceil(x_testImg.shape[0]/1024))\n",
        "    \n",
        "\n",
        "    loss, acc = Models.evaluate_generator(test_set,steps=size)\n",
        "    a.append(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For run : 0\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 9s 104ms/step - loss: 2.9750 - accuracy: 0.7998 - val_loss: 3.0474 - val_accuracy: 0.6408\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 7s 101ms/step - loss: 2.9579 - accuracy: 0.8198 - val_loss: 3.0091 - val_accuracy: 0.6449\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9571 - accuracy: 0.8202 - val_loss: 2.9679 - val_accuracy: 0.7095\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9567 - accuracy: 0.8209 - val_loss: 2.9574 - val_accuracy: 0.7092\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9563 - accuracy: 0.8217 - val_loss: 2.9562 - val_accuracy: 0.7101\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9561 - accuracy: 0.8223 - val_loss: 2.9557 - val_accuracy: 0.7110\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9560 - accuracy: 0.8232 - val_loss: 2.9554 - val_accuracy: 0.7118\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9559 - accuracy: 0.8240 - val_loss: 2.9556 - val_accuracy: 0.7135\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9559 - accuracy: 0.8251 - val_loss: 2.9555 - val_accuracy: 0.7158\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9558 - accuracy: 0.8264 - val_loss: 2.9554 - val_accuracy: 0.7155\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9557 - accuracy: 0.8269 - val_loss: 2.9556 - val_accuracy: 0.7172\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9557 - accuracy: 0.8281 - val_loss: 2.9552 - val_accuracy: 0.7116\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9557 - accuracy: 0.8299 - val_loss: 2.9552 - val_accuracy: 0.7194\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9556 - accuracy: 0.1651 - val_loss: 2.9551 - val_accuracy: 0.7194\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9556 - accuracy: 0.1652 - val_loss: 2.9552 - val_accuracy: 0.7242\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9556 - accuracy: 0.1653 - val_loss: 2.9551 - val_accuracy: 0.7261\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9555 - accuracy: 0.1654 - val_loss: 2.9551 - val_accuracy: 0.7257\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9555 - accuracy: 0.1655 - val_loss: 2.9553 - val_accuracy: 0.7282\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9555 - accuracy: 0.1656 - val_loss: 2.9550 - val_accuracy: 0.7292\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9555 - accuracy: 0.1657 - val_loss: 2.9550 - val_accuracy: 0.7269\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9555 - accuracy: 0.1659 - val_loss: 2.9551 - val_accuracy: 0.7333\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8403 - val_loss: 2.9555 - val_accuracy: 0.7325\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 7s 104ms/step - loss: 2.9555 - accuracy: 0.8417 - val_loss: 2.9550 - val_accuracy: 0.7356\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8433 - val_loss: 2.9550 - val_accuracy: 0.7320\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8103 - val_loss: 2.9550 - val_accuracy: 0.7385\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8460 - val_loss: 2.9549 - val_accuracy: 0.7388\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8478 - val_loss: 2.9552 - val_accuracy: 0.7391\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8491 - val_loss: 2.9548 - val_accuracy: 0.7391\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8506 - val_loss: 2.9549 - val_accuracy: 0.7435\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 7s 104ms/step - loss: 2.9553 - accuracy: 0.8524 - val_loss: 2.9549 - val_accuracy: 0.7427\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8534 - val_loss: 2.9549 - val_accuracy: 0.7103\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9554 - accuracy: 0.8550 - val_loss: 2.9549 - val_accuracy: 0.7452\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8561 - val_loss: 2.9549 - val_accuracy: 0.7472\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8570 - val_loss: 2.9548 - val_accuracy: 0.7497\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8577 - val_loss: 2.9548 - val_accuracy: 0.7468\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8590 - val_loss: 2.9548 - val_accuracy: 0.7466\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8604 - val_loss: 2.9549 - val_accuracy: 0.7490\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8615 - val_loss: 2.9548 - val_accuracy: 0.7426\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9553 - accuracy: 0.8630 - val_loss: 2.9548 - val_accuracy: 0.7535\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8638 - val_loss: 2.9547 - val_accuracy: 0.7567\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8648 - val_loss: 2.9547 - val_accuracy: 0.7538\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8660 - val_loss: 2.9548 - val_accuracy: 0.7564\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8674 - val_loss: 2.9547 - val_accuracy: 0.7571\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8678 - val_loss: 2.9548 - val_accuracy: 0.7577\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8691 - val_loss: 2.9547 - val_accuracy: 0.7581\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8703 - val_loss: 2.9548 - val_accuracy: 0.7580\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8712 - val_loss: 2.9548 - val_accuracy: 0.7629\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8732 - val_loss: 2.9548 - val_accuracy: 0.7609\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8744 - val_loss: 2.9547 - val_accuracy: 0.7621\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8755 - val_loss: 2.9547 - val_accuracy: 0.7643\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8758 - val_loss: 2.9547 - val_accuracy: 0.7668\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8772 - val_loss: 2.9548 - val_accuracy: 0.7667\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8780 - val_loss: 2.9548 - val_accuracy: 0.7678\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8794 - val_loss: 2.9549 - val_accuracy: 0.7701\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9553 - accuracy: 0.8804 - val_loss: 2.9547 - val_accuracy: 0.7734\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9552 - accuracy: 0.8811 - val_loss: 2.9547 - val_accuracy: 0.7793\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9552 - accuracy: 0.8820 - val_loss: 2.9549 - val_accuracy: 0.7778\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8826 - val_loss: 2.9549 - val_accuracy: 0.7713\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8845 - val_loss: 2.9547 - val_accuracy: 0.7847\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8854 - val_loss: 2.9548 - val_accuracy: 0.7165\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8859 - val_loss: 2.9548 - val_accuracy: 0.7873\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8866 - val_loss: 2.9547 - val_accuracy: 0.7854\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8875 - val_loss: 2.9547 - val_accuracy: 0.7876\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8888 - val_loss: 2.9547 - val_accuracy: 0.8005\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8900 - val_loss: 2.9546 - val_accuracy: 0.8014\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8912 - val_loss: 2.9548 - val_accuracy: 0.8030\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8928 - val_loss: 2.9548 - val_accuracy: 0.8037\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8940 - val_loss: 2.9547 - val_accuracy: 0.8020\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.8954 - val_loss: 2.9547 - val_accuracy: 0.8031\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8963 - val_loss: 2.9546 - val_accuracy: 0.8051\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.8970 - val_loss: 2.9547 - val_accuracy: 0.8067\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.8986 - val_loss: 2.9546 - val_accuracy: 0.8077\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.8994 - val_loss: 2.9546 - val_accuracy: 0.8069\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.8995 - val_loss: 2.9547 - val_accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.9005 - val_loss: 2.9546 - val_accuracy: 0.8195\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9022 - val_loss: 2.9546 - val_accuracy: 0.8199\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9038 - val_loss: 2.9547 - val_accuracy: 0.8122\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.9048 - val_loss: 2.9547 - val_accuracy: 0.8141\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9052 - val_loss: 2.9549 - val_accuracy: 0.8152\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.9068 - val_loss: 2.9547 - val_accuracy: 0.8113\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9075 - val_loss: 2.9547 - val_accuracy: 0.8055\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9552 - accuracy: 0.9084 - val_loss: 2.9546 - val_accuracy: 0.8025\n",
            "Epoch 165/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9102 - val_loss: 2.9547 - val_accuracy: 0.8015\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9120 - val_loss: 2.9547 - val_accuracy: 0.8076\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9132 - val_loss: 2.9546 - val_accuracy: 0.8110\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9143 - val_loss: 2.9547 - val_accuracy: 0.8131\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9148 - val_loss: 2.9546 - val_accuracy: 0.8126\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9161 - val_loss: 2.9547 - val_accuracy: 0.8148\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9167 - val_loss: 2.9546 - val_accuracy: 0.8174\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9177 - val_loss: 2.9546 - val_accuracy: 0.8151\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9184 - val_loss: 2.9546 - val_accuracy: 0.8047\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9195 - val_loss: 2.9546 - val_accuracy: 0.8088\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9209 - val_loss: 2.9546 - val_accuracy: 0.8080\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9216 - val_loss: 2.9547 - val_accuracy: 0.8088\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9229 - val_loss: 2.9546 - val_accuracy: 0.8197\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9240 - val_loss: 2.9546 - val_accuracy: 0.8144\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9249 - val_loss: 2.9546 - val_accuracy: 0.8132\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9262 - val_loss: 2.9547 - val_accuracy: 0.8137\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9551 - accuracy: 0.9271 - val_loss: 2.9546 - val_accuracy: 0.8150\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 7s 103ms/step - loss: 2.9551 - accuracy: 0.9280 - val_loss: 2.9546 - val_accuracy: 0.8153\n",
            "For run : 1\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 9s 110ms/step - loss: 2.9750 - accuracy: 0.7998 - val_loss: 3.0474 - val_accuracy: 0.7408\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9579 - accuracy: 0.8198 - val_loss: 3.0091 - val_accuracy: 0.7449\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9571 - accuracy: 0.8202 - val_loss: 2.9679 - val_accuracy: 0.7595\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9567 - accuracy: 0.8209 - val_loss: 2.9574 - val_accuracy: 0.7592\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9563 - accuracy: 0.8217 - val_loss: 2.9562 - val_accuracy: 0.7501\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9561 - accuracy: 0.8223 - val_loss: 2.9557 - val_accuracy: 0.7510\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9560 - accuracy: 0.8232 - val_loss: 2.9554 - val_accuracy: 0.7518\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9559 - accuracy: 0.8240 - val_loss: 2.9556 - val_accuracy: 0.7535\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 7s 105ms/step - loss: 2.9559 - accuracy: 0.8251 - val_loss: 2.9555 - val_accuracy: 0.7558\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9558 - accuracy: 0.8264 - val_loss: 2.9554 - val_accuracy: 0.7555\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9557 - accuracy: 0.8269 - val_loss: 2.9556 - val_accuracy: 0.7572\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9557 - accuracy: 0.8281 - val_loss: 2.9552 - val_accuracy: 0.7516\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9557 - accuracy: 0.8299 - val_loss: 2.9552 - val_accuracy: 0.7594\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9556 - accuracy: 0.1651 - val_loss: 2.9551 - val_accuracy: 0.7594\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9556 - accuracy: 0.1652 - val_loss: 2.9552 - val_accuracy: 0.7642\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9556 - accuracy: 0.1653 - val_loss: 2.9551 - val_accuracy: 0.7661\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9555 - accuracy: 0.1654 - val_loss: 2.9551 - val_accuracy: 0.7657\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9555 - accuracy: 0.1655 - val_loss: 2.9553 - val_accuracy: 0.7682\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9555 - accuracy: 0.1656 - val_loss: 2.9550 - val_accuracy: 0.7692\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9555 - accuracy: 0.1657 - val_loss: 2.9550 - val_accuracy: 0.7669\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9555 - accuracy: 0.1659 - val_loss: 2.9551 - val_accuracy: 0.7733\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8403 - val_loss: 2.9555 - val_accuracy: 0.7725\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9555 - accuracy: 0.8417 - val_loss: 2.9550 - val_accuracy: 0.7756\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8433 - val_loss: 2.9550 - val_accuracy: 0.7720\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8448 - val_loss: 2.9550 - val_accuracy: 0.7785\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8460 - val_loss: 2.9549 - val_accuracy: 0.7788\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8478 - val_loss: 2.9552 - val_accuracy: 0.7791\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8491 - val_loss: 2.9548 - val_accuracy: 0.7791\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8506 - val_loss: 2.9549 - val_accuracy: 0.7735\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9553 - accuracy: 0.8524 - val_loss: 2.9549 - val_accuracy: 0.7727\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8534 - val_loss: 2.9549 - val_accuracy: 0.7740\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9554 - accuracy: 0.8550 - val_loss: 2.9549 - val_accuracy: 0.7752\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8561 - val_loss: 2.9549 - val_accuracy: 0.7772\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8570 - val_loss: 2.9548 - val_accuracy: 0.7897\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8577 - val_loss: 2.9548 - val_accuracy: 0.7468\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8590 - val_loss: 2.9548 - val_accuracy: 0.7866\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8604 - val_loss: 2.9549 - val_accuracy: 0.7890\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8615 - val_loss: 2.9548 - val_accuracy: 0.7826\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9553 - accuracy: 0.8630 - val_loss: 2.9548 - val_accuracy: 0.7835\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8638 - val_loss: 2.9547 - val_accuracy: 0.7867\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8648 - val_loss: 2.9547 - val_accuracy: 0.7838\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8660 - val_loss: 2.9548 - val_accuracy: 0.7864\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8674 - val_loss: 2.9547 - val_accuracy: 0.7871\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8678 - val_loss: 2.9548 - val_accuracy: 0.7877\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8691 - val_loss: 2.9547 - val_accuracy: 0.7881\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8703 - val_loss: 2.9548 - val_accuracy: 0.7880\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8712 - val_loss: 2.9548 - val_accuracy: 0.7929\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8732 - val_loss: 2.9548 - val_accuracy: 0.7909\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8744 - val_loss: 2.9547 - val_accuracy: 0.7921\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8755 - val_loss: 2.9547 - val_accuracy: 0.7943\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8758 - val_loss: 2.9547 - val_accuracy: 0.7968\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8772 - val_loss: 2.9548 - val_accuracy: 0.7967\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8780 - val_loss: 2.9548 - val_accuracy: 0.7878\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8794 - val_loss: 2.9549 - val_accuracy: 0.7801\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9553 - accuracy: 0.8804 - val_loss: 2.9547 - val_accuracy: 0.7834\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9552 - accuracy: 0.8811 - val_loss: 2.9547 - val_accuracy: 0.7893\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9552 - accuracy: 0.8820 - val_loss: 2.9549 - val_accuracy: 0.7878\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8826 - val_loss: 2.9549 - val_accuracy: 0.7813\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8845 - val_loss: 2.9547 - val_accuracy: 0.7847\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8854 - val_loss: 2.9548 - val_accuracy: 0.7858\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8859 - val_loss: 2.9548 - val_accuracy: 0.7873\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8866 - val_loss: 2.9547 - val_accuracy: 0.7854\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8875 - val_loss: 2.9547 - val_accuracy: 0.7876\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8888 - val_loss: 2.9547 - val_accuracy: 0.7805\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8900 - val_loss: 2.9546 - val_accuracy: 0.7814\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8912 - val_loss: 2.9548 - val_accuracy: 0.7830\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8928 - val_loss: 2.9548 - val_accuracy: 0.7837\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8940 - val_loss: 2.9547 - val_accuracy: 0.7820\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.8954 - val_loss: 2.9547 - val_accuracy: 0.7831\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8963 - val_loss: 2.9546 - val_accuracy: 0.7851\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.8970 - val_loss: 2.9547 - val_accuracy: 0.7867\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.8986 - val_loss: 2.9546 - val_accuracy: 0.7877\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.8994 - val_loss: 2.9546 - val_accuracy: 0.7869\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.8995 - val_loss: 2.9547 - val_accuracy: 0.7800\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.9005 - val_loss: 2.9546 - val_accuracy: 0.7995\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9022 - val_loss: 2.9546 - val_accuracy: 0.7999\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9038 - val_loss: 2.9547 - val_accuracy: 0.7922\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.9048 - val_loss: 2.9547 - val_accuracy: 0.7941\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9052 - val_loss: 2.9549 - val_accuracy: 0.7952\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.9068 - val_loss: 2.9547 - val_accuracy: 0.7913\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9075 - val_loss: 2.9547 - val_accuracy: 0.8055\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9552 - accuracy: 0.9084 - val_loss: 2.9546 - val_accuracy: 0.8025\n",
            "Epoch 165/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9102 - val_loss: 2.9547 - val_accuracy: 0.8015\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9120 - val_loss: 2.9547 - val_accuracy: 0.8076\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9132 - val_loss: 2.9546 - val_accuracy: 0.8044\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9143 - val_loss: 2.9547 - val_accuracy: 0.8031\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9148 - val_loss: 2.9546 - val_accuracy: 0.8126\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9161 - val_loss: 2.9547 - val_accuracy: 0.8132\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9167 - val_loss: 2.9546 - val_accuracy: 0.8150\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9177 - val_loss: 2.9546 - val_accuracy: 0.8151\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9546 - accuracy: 0.9184 - val_loss: 2.9546 - val_accuracy: 0.8147\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9546 - accuracy: 0.9195 - val_loss: 2.9546 - val_accuracy: 0.8145\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9209 - val_loss: 2.9546 - val_accuracy: 0.8181\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9216 - val_loss: 2.9547 - val_accuracy: 0.8188\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9229 - val_loss: 2.9262 - val_accuracy: 0.8197\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9546 - accuracy: 0.9240 - val_loss: 2.9546 - val_accuracy: 0.8110\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9546 - accuracy: 0.9249 - val_loss: 2.9546 - val_accuracy: 0.8148\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9551 - accuracy: 0.9262 - val_loss: 2.9262 - val_accuracy: 0.8137\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9551 - accuracy: 0.9271 - val_loss: 2.9262 - val_accuracy: 0.8174\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9546 - accuracy: 0.9195 - val_loss: 2.9579 - val_accuracy: 0.8170\n",
            "For run : 2\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 9s 101ms/step - loss: 2.9750 - accuracy: 0.7998 - val_loss: 3.0474 - val_accuracy: 0.7503\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9579 - accuracy: 0.8198 - val_loss: 3.0091 - val_accuracy: 0.7511\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9571 - accuracy: 0.8202 - val_loss: 2.9679 - val_accuracy: 0.7529\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9567 - accuracy: 0.8209 - val_loss: 2.9574 - val_accuracy: 0.7496\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9563 - accuracy: 0.8217 - val_loss: 2.9562 - val_accuracy: 0.7405\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 7s 93ms/step - loss: 2.9561 - accuracy: 0.8223 - val_loss: 2.9557 - val_accuracy: 0.7467\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9560 - accuracy: 0.8232 - val_loss: 2.9554 - val_accuracy: 0.7519\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9559 - accuracy: 0.8240 - val_loss: 2.9556 - val_accuracy: 0.7537\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9559 - accuracy: 0.8251 - val_loss: 2.9555 - val_accuracy: 0.7563\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9558 - accuracy: 0.8264 - val_loss: 2.9554 - val_accuracy: 0.7584\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9557 - accuracy: 0.8269 - val_loss: 2.9556 - val_accuracy: 0.7521\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9557 - accuracy: 0.8281 - val_loss: 2.9552 - val_accuracy: 0.7569\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9557 - accuracy: 0.8299 - val_loss: 2.9552 - val_accuracy: 0.7542\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9556 - accuracy: 0.1651 - val_loss: 2.9551 - val_accuracy: 0.7548\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9556 - accuracy: 0.1652 - val_loss: 2.9552 - val_accuracy: 0.7523\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9556 - accuracy: 0.1653 - val_loss: 2.9551 - val_accuracy: 0.7567\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9555 - accuracy: 0.1654 - val_loss: 2.9551 - val_accuracy: 0.7576\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9555 - accuracy: 0.1655 - val_loss: 2.9553 - val_accuracy: 0.7628\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9555 - accuracy: 0.1656 - val_loss: 2.9550 - val_accuracy: 0.7602\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9555 - accuracy: 0.1657 - val_loss: 2.9550 - val_accuracy: 0.7621\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9555 - accuracy: 0.1659 - val_loss: 2.9551 - val_accuracy: 0.7632\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8403 - val_loss: 2.9555 - val_accuracy: 0.7656\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9555 - accuracy: 0.8417 - val_loss: 2.9550 - val_accuracy: 0.7595\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8433 - val_loss: 2.9550 - val_accuracy: 0.7528\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8448 - val_loss: 2.9550 - val_accuracy: 0.7587\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8460 - val_loss: 2.9549 - val_accuracy: 0.7661\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8478 - val_loss: 2.9552 - val_accuracy: 0.7712\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8491 - val_loss: 2.9548 - val_accuracy: 0.7728\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8506 - val_loss: 2.9549 - val_accuracy: 0.7714\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9553 - accuracy: 0.8524 - val_loss: 2.9549 - val_accuracy: 0.7758\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8534 - val_loss: 2.9549 - val_accuracy: 0.7761\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9554 - accuracy: 0.8550 - val_loss: 2.9549 - val_accuracy: 0.7729\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8561 - val_loss: 2.9549 - val_accuracy: 0.7757\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8570 - val_loss: 2.9548 - val_accuracy: 0.7879\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8577 - val_loss: 2.9548 - val_accuracy: 0.7824\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8590 - val_loss: 2.9548 - val_accuracy: 0.7761\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8604 - val_loss: 2.9549 - val_accuracy: 0.7806\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8615 - val_loss: 2.9548 - val_accuracy: 0.7819\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9553 - accuracy: 0.8630 - val_loss: 2.9548 - val_accuracy: 0.7854\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8638 - val_loss: 2.9547 - val_accuracy: 0.7838\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8648 - val_loss: 2.9547 - val_accuracy: 0.7814\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8660 - val_loss: 2.9548 - val_accuracy: 0.7869\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8674 - val_loss: 2.9547 - val_accuracy: 0.7894\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8678 - val_loss: 2.9548 - val_accuracy: 0.7892\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8691 - val_loss: 2.9547 - val_accuracy: 0.7851\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8703 - val_loss: 2.9548 - val_accuracy: 0.7856\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8712 - val_loss: 2.9548 - val_accuracy: 0.7814\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8732 - val_loss: 2.9548 - val_accuracy: 0.7938\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8744 - val_loss: 2.9547 - val_accuracy: 0.7845\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8755 - val_loss: 2.9547 - val_accuracy: 0.7891\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8758 - val_loss: 2.9547 - val_accuracy: 0.7911\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8772 - val_loss: 2.9548 - val_accuracy: 0.7908\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8780 - val_loss: 2.9548 - val_accuracy: 0.7943\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8794 - val_loss: 2.9549 - val_accuracy: 0.7913\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9553 - accuracy: 0.8804 - val_loss: 2.9547 - val_accuracy: 0.7948\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9552 - accuracy: 0.8811 - val_loss: 2.9547 - val_accuracy: 0.7936\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9552 - accuracy: 0.8820 - val_loss: 2.9549 - val_accuracy: 0.7914\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8826 - val_loss: 2.9549 - val_accuracy: 0.7983\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8845 - val_loss: 2.9547 - val_accuracy: 0.7947\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8854 - val_loss: 2.9548 - val_accuracy: 0.7962\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8859 - val_loss: 2.9548 - val_accuracy: 0.7954\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8866 - val_loss: 2.9547 - val_accuracy: 0.7926\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8875 - val_loss: 2.9547 - val_accuracy: 0.7914\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8888 - val_loss: 2.9547 - val_accuracy: 0.7946\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8900 - val_loss: 2.9546 - val_accuracy: 0.7928\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8912 - val_loss: 2.9548 - val_accuracy: 0.7946\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8928 - val_loss: 2.9548 - val_accuracy: 0.7941\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8940 - val_loss: 2.9547 - val_accuracy: 0.7984\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.8954 - val_loss: 2.9547 - val_accuracy: 0.7924\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8963 - val_loss: 2.9546 - val_accuracy: 0.7916\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.8970 - val_loss: 2.9547 - val_accuracy: 0.7936\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.8986 - val_loss: 2.9546 - val_accuracy: 0.7942\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.8994 - val_loss: 2.9546 - val_accuracy: 0.7986\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.8995 - val_loss: 2.9547 - val_accuracy: 0.7924\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.9005 - val_loss: 2.9546 - val_accuracy: 0.7916\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9022 - val_loss: 2.9546 - val_accuracy: 0.7948\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9038 - val_loss: 2.9547 - val_accuracy: 0.7914\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.9048 - val_loss: 2.9547 - val_accuracy: 0.8014\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9052 - val_loss: 2.9549 - val_accuracy: 0.8027\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.9068 - val_loss: 2.9547 - val_accuracy: 0.8014\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9075 - val_loss: 2.9547 - val_accuracy: 0.8011\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9552 - accuracy: 0.9084 - val_loss: 2.9546 - val_accuracy: 0.8027\n",
            "Epoch 165/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9102 - val_loss: 2.9547 - val_accuracy: 0.8019\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9120 - val_loss: 2.9547 - val_accuracy: 0.8067\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9132 - val_loss: 2.9546 - val_accuracy: 0.8065\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9143 - val_loss: 2.9547 - val_accuracy: 0.8013\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9148 - val_loss: 2.9546 - val_accuracy: 0.8062\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9161 - val_loss: 2.9547 - val_accuracy: 0.8023\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9167 - val_loss: 2.9546 - val_accuracy: 0.8094\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9177 - val_loss: 2.9546 - val_accuracy: 0.8047\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9184 - val_loss: 2.9262 - val_accuracy: 0.8043\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9195 - val_loss: 2.9262 - val_accuracy: 0.8071\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9209 - val_loss: 2.9546 - val_accuracy: 0.8093\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9216 - val_loss: 2.9547 - val_accuracy: 0.8074\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9229 - val_loss: 2.9262 - val_accuracy: 0.8108\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9547 - accuracy: 0.9240 - val_loss: 2.9262 - val_accuracy: 0.8149\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9551 - accuracy: 0.9249 - val_loss: 2.9546 - val_accuracy: 0.8195\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9547 - accuracy: 0.9262 - val_loss: 2.9262 - val_accuracy: 0.8110\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 7s 92ms/step - loss: 2.9551 - accuracy: 0.9229 - val_loss: 2.9262 - val_accuracy: 0.8158\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 7s 97ms/step - loss: 2.9547 - accuracy: 0.9216 - val_loss: 2.9546 - val_accuracy: 0.8139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lZEwgyPOASvZ",
        "outputId": "0f98fdc1-03d9-497c-8c36-15c4ea1ce6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Finding the mean of the 3 runs and calculating the \n",
        "#final average testing accuracy\n",
        "acc = np.mean(a)\n",
        "\n",
        "print(\"Average testing accuracy : \" + str(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average testing accuracy : 0.8151"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}